# encoding: utf-8
'''
The MIT License (MIT)
Copyright © 2023 Chris Carl <chrisbcarl@outlook.com>
Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the “Software”), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all
  copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.

Author:     Chris Carl <chrisbcarl@outlook.com>
Date:       2024-09-26
Modified:   2024-09-26

Modified:
    2025-08-02 - chrisbcarl - added perf+fill+read and smartmon
    2025-08-01 - chrisbcarl - changed to chriscarl.tools.analyze-disk-performance
                              created the 'health' module which is designed to rip through all disks
                              added crystaldiskinfo utilization, we'll see how it goes after testing.
    2024-09-28 - chrisbcarl - added "write" mode, much easier.
    2024-09-26 - chrisbcarl - complete rewrite with different modes this time
    2023-07-05 - chrisbcarl - init commit, behaves like sequential write/readback, thats it.

TODO:
    - move toward list operations rather than explicitly perf + write, like you can mix perf write loop etc, implying
        the bytearray generated by perf is used by write and loop
    - deal with the situation where create_bytearray would result in a bytearray the size larger than the universe.
        better would be to make some object that when you ask for an index or the next byte,
        it GENRATES it, is writable, etc...
    - dynamic crystaldiskinfo txt

Examples:
    1. Find performance sweetspot and fill the disk at partition D:/
        python main.py perf+fill --data-filepath D:/temp
    2. Evaluate overall health on all newly inserted disks
        python main.py health --ignore-partitions C --log-level DEBUG
'''
# stdlib
from __future__ import print_function, division
import os
import sys
import re
import csv
import time
import copy
import json
import shutil
import string
import random
import logging
import argparse
import datetime
import threading
import subprocess
import multiprocessing
from typing import Tuple, Dict

# 3rd party
import pandas as pd
import psutil

SCRIPT_DIRPATH = os.path.abspath(os.path.dirname(__file__))
NOW = datetime.datetime.now()
TEMP_DIRPATH = '/temp' if sys.platform == 'win32' else '/tmp'
TEMP_DIRPATH = os.path.join(TEMP_DIRPATH, NOW.strftime('%Y%m%d-%H%M'))  # %S
TEMP_DIRPATH = os.path.abspath(TEMP_DIRPATH)
DRIVE, _ = os.path.splitdrive(TEMP_DIRPATH)
DATA_FILEPATH = os.path.join(TEMP_DIRPATH, 'data.dat')
PERF_FILEPATH = os.path.join(TEMP_DIRPATH, 'perf.csv')
OPERATIONS = ['perf', 'fill', 'perf+fill', 'loop', 'write', 'perf+write', 'health', 'perf+fill+read', 'smartmon']
CPU_COUNT = multiprocessing.cpu_count()
LOG_LEVELS = list(logging._nameToLevel)  # pylint: disable=(protected-access)
LOG_LEVEL = 'INFO'
VALUE = -1
DURATION = 2
ITERATIONS = 5
SIZE = 1
CRYSTALDISKINFO_EXE = 'DiskInfo64.exe' if sys.platform == 'win32' else 'DiskInfo64'
CRYSTALDISKINFO_TXT = ''
PERIOD = 15
LOOPS = -1


class NiceFormatter(
    argparse.ArgumentDefaultsHelpFormatter, argparse.RawTextHelpFormatter, argparse.RawDescriptionHelpFormatter
):
    pass


def create_bytearray(count, value=VALUE):
    if value == VALUE:
        new = bytearray(random.randint(0, 255) for _ in range(count))
    else:
        new = bytearray(value for _ in range(count))
    return new


def create_bytearray_killobytes(count, value=VALUE):
    '''
    Description:
        create a bytearray by repeating only 1kb until the requested count
        the motivation is i've found generating 1MB takes about .15s,
            but generating 10MB takes 20s, so its not growing linearly.
    '''
    logging.debug('%s, value=%s', count, value)
    killobyte = create_bytearray(1024, value=value)
    killobytes_array = bytearray()
    for _ in range(count):
        killobytes_array.extend(copy.deepcopy(killobyte))
    logging.debug('created byte array of size %0.3f MB', len(killobytes_array) / 1024**2)
    return killobytes_array


def disk_usage_monitor(event, drive=DRIVE):
    # type: (threading.Event, str) -> None
    while not event.is_set():
        du = psutil.disk_usage(drive)
        logging.info('disk usage: %s%%', du.percent)
        for _ in range(100):
            time.sleep(1 / 100)
            if event.is_set():
                break


def validate_kwargs(
    operation=OPERATIONS[0],
    log_level='INFO',
    value=VALUE,
    size=SIZE,
    duration=DURATION,
    iterations=ITERATIONS,
    no_optimizations=False,
    data_filepath=DATA_FILEPATH,
    perf_filepath=PERF_FILEPATH,
    ignore_partitions=None,
    period=PERIOD,
    loops=LOOPS,
):
    if operation not in OPERATIONS:
        raise KeyError(f'operation {operation!r} does not exist, use one of {OPERATIONS}!')
    if log_level not in LOG_LEVELS:
        raise KeyError(f'log_level {log_level!r} does not exist!')
    if value != -1:
        if value < 0 and 255 < value:
            raise ValueError('value must be a value between [0,255] or -1')
    if size < 1:
        raise ValueError('duration must be a postive int, are you nuts?')
    if duration < 0 and duration != -1:
        raise ValueError('duration must be a postive num (or -1), are you nuts?')
    if iterations < 0:
        raise ValueError('iterations must be a postive int, are you nuts?')
    if not isinstance(no_optimizations, bool):
        raise TypeError(f'no_optimizations must be of type bool, provided {type(no_optimizations)}')
    for filepath in [data_filepath, perf_filepath]:
        if not os.path.isdir(os.path.dirname(filepath)):
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
    if isinstance(ignore_partitions, list):
        for ignore_partition in ignore_partitions:
            if ignore_partition not in string.ascii_uppercase:
                raise ValueError(f'ignore_partition {ignore_partition!r} not in expected possibilities!')
    if period < 0:
        raise ValueError('period must be positive!')
    if loops < 0 and loops != -1:
        raise ValueError('loops must be positive!')


def write_byte_array_continuously(byte_array, data_filepath=DATA_FILEPATH, duration=DURATION, iterations=ITERATIONS):
    # type: (bytearray, str, float, int) -> Tuple[int, float, int]
    '''
    Description:
        given a bytearray, write it to the disk in write mode fashion until the duration or iterations has been exceeded
    Arguments:
        duration: float
            in seconds, how long should it go for? exec ends after duration exceeded or iteration exceeded
        iteration: int
            in ints, many times? exec ends after duration exceeded or iteration exceeded
    Returns:
        Tuple[int, float, int]
            bytes written, elapsed in seconds, iterations achieved
    '''
    validate_kwargs(data_filepath=data_filepath, duration=duration, iterations=iterations)
    logging.info('data_filepath="%s", duration=%s, iterations=%s', data_filepath, duration, iterations)
    with open(data_filepath, 'wb'):
        pass
    original_size = os.path.getsize(data_filepath)
    with open(data_filepath, 'wb') as wb:
        start = time.time()
        iteration = 0
        while time.time() - start < duration or iteration < iterations:
            wb.write(byte_array)
            iteration += 1
        end = time.time()
    bytes_written = os.path.getsize(data_filepath) - original_size
    elapsed = end - start
    throughput = bytes_written / 1024**2 / elapsed
    logging.debug(
        'bytes_written=%s, elapsed=%s, iteration=%s, throughput=%0.3f MB/s', bytes_written, elapsed, iteration,
        throughput
    )
    return bytes_written, elapsed, iteration


def write_byte_array_contiguously(byte_array, data_filepath=DATA_FILEPATH):
    # type: (bytearray, str) -> None
    '''
    Description:
        given a bytearray, write it to the disk in an appending fashion,
            and when you inevitably overshoot, value in 1mb increments
    Arguments:
    Returns:
    '''
    validate_kwargs(data_filepath=data_filepath)
    logging.info('data_filepath="%s"', data_filepath)

    drive, _ = os.path.splitdrive(os.path.abspath(data_filepath))

    one_mb_bytes = (1024**2)
    byte_array_bytes = len(byte_array)
    event = threading.Event()
    t = threading.Thread(target=disk_usage_monitor, args=(event, ), kwargs=dict(drive=drive), daemon=True)
    t.start()
    try:
        with open(data_filepath, 'ab') as wb:
            while psutil.disk_usage(drive).free > byte_array_bytes:
                wb.write(byte_array)
        # writing in 1mb chunks
        with open(data_filepath, 'ab') as wb:
            for i in range(byte_array_bytes // one_mb_bytes):
                if psutil.disk_usage(drive).free > one_mb_bytes:
                    one_mb_array = byte_array[i * one_mb_bytes:(i + 1) * one_mb_bytes]
                    wb.write(one_mb_array)
                else:
                    break
    except KeyboardInterrupt:
        logging.info('cancelling')
    except OSError:
        logging.info('done')
    finally:
        event.set()
    du = psutil.disk_usage(drive)
    logging.debug('disk usage: %s%%', du.percent)


def create_byte_array_high_throughput(data_filepath=DATA_FILEPATH, perf_filepath=PERF_FILEPATH, value=VALUE):
    # type: (str, str, int) -> bytearray
    '''
    Description:
        create a bunch of byte_arrays of different sizes and pick the one with the highest write throughput
    Arguments:
        fill: int
            default -1
            from 0-255, do you want the bytes to be all the same, or -1 for random?
    Returns:
        bytearray
    '''
    validate_kwargs(value=value, data_filepath=data_filepath, perf_filepath=perf_filepath)
    logging.info('data_filepath="%s", perf_filepath="%s", value=%s', data_filepath, perf_filepath, value)
    rows = []
    sweetspot_bytearray = bytearray()
    sweetspot_killobytes = 0
    sweetspot_rate = 0.0
    killobytes_list = [1, 4, 32, 128]
    killobytes_list.extend([1024 * ele for ele in killobytes_list])
    killobytes_list.extend([ele * 2 for ele in killobytes_list] + [ele * 3 for ele in killobytes_list])
    for killobytes in sorted(killobytes_list):
        megabytes = killobytes / 1024
        byte_array = create_bytearray_killobytes(killobytes, value=value)
        bytes_written_bytes, elapsed, iteration = write_byte_array_continuously(byte_array, data_filepath)
        bytes_written_mb = bytes_written_bytes / 1024**2
        rate = bytes_written_mb / elapsed
        if rate > sweetspot_rate:
            sweetspot_rate = rate
            sweetspot_killobytes = killobytes
            sweetspot_bytearray = byte_array
        logging.info(
            '%s kb - %0.3f mb - %0.3f mb/s over %0.3f sec - iteration %s', killobytes, megabytes, rate, elapsed,
            iteration
        )
        row = {'kb': killobytes, 'mb': megabytes, 'rate': rate, 'elapsed': elapsed, 'iteration': iteration}
        rows.append(row)
    df = pd.DataFrame(rows)
    logging.debug('\n%s', df)
    df.to_csv(perf_filepath, index=False)
    logging.info('%s kb - %0.3f mb/s - sweetspot', sweetspot_killobytes, sweetspot_rate)
    return sweetspot_bytearray


def write_bytearray_to_disk(byte_array, size=-1, data_filepath=DATA_FILEPATH, randomness=True):
    # type: (bytearray, int, str, bool) -> None
    '''
    Description:
        cleverly write a byte_array to the disk,
        especially if the provided array is meant to be repeatedly written until it hits the right size.
    '''
    if size == -1:
        size = len(byte_array)
    with open(data_filepath, 'wb') as wb:
        pass
    iterations = size // len(byte_array)
    with open(data_filepath, 'ab') as wb:
        for i in range(iterations):
            # basically "fake" randomness even further by starting at different points within the already created one.
            # if fill is provided, they're all constants anyway
            if randomness:
                midpoint = random.randint(0, len(byte_array) - 1)
                wb.write(byte_array[midpoint:])
                wb.write(byte_array[0:midpoint])
            else:
                wb.write(byte_array)
            logging.debug(
                '%0.3f%% or %0.3f MB written', (i + 1) / (iterations + 1) * 100,
                os.path.getsize(data_filepath) / 1024**2
            )
        remainder = size - os.path.getsize(data_filepath)
        wb.write(byte_array[0:remainder])
        logging.debug(
            '%0.3f%% or %0.3f MB written', (i + 2) / (iterations + 1) * 100,
            os.path.getsize(data_filepath) / 1024**2
        )


def read_bytearray_from_disk(byte_array, data_filepath=DATA_FILEPATH):
    iterations = os.path.getsize(data_filepath) // len(byte_array) + 1
    with open(data_filepath, 'rb') as rb:
        i = 0
        read_array = rb.read(len(byte_array))
        while read_array:
            if len(read_array) == len(byte_array):
                assert read_array == byte_array, (
                    f'on iteration {i}, full array read != write!\n'
                    f'Expected {byte_array}\n'
                    f'Read {read_array}'
                )
            else:
                assert read_array == byte_array[:len(read_array)], (
                    f'on iteration {i}, sub array read != write!\n'
                    f'Expected {byte_array}\n'
                    f'Read {read_array}'
                )
            logging.debug('%0.3f%% or %0.3f MB read', (i + 1) / (iterations) * 100, len(byte_array) * (i + 1) / 1024**2)

            read_array = rb.read(len(byte_array))
            i += 1


def generate_and_write_bytearray(size, value=VALUE, no_optimizations=False, data_filepath=DATA_FILEPATH):
    # type: (int, int, bool, str) -> None
    '''
    Description:
        basically just create a file of a certain size.
        TODO: be wary of too large sizes on no_optimizations
    '''
    logging.info('%s, value=%s, no_optimizations=%s, data_filepath="%s"', size, value, no_optimizations, data_filepath)
    if no_optimizations:
        byte_array = create_bytearray(size, value=value)
    else:
        if size < 1024**2:
            byte_array = create_bytearray(size, value=value)
        else:
            byte_array = create_bytearray(1024**2, value=value)  # 1mb is pretty performant no matter what
    write_bytearray_to_disk(byte_array, size=size, data_filepath=DATA_FILEPATH)


def perf_fill_read(data_filepath=DATA_FILEPATH, perf_filepath=PERF_FILEPATH, value=VALUE, loops=-1, duration=-1):
    sweetspot_byte_array = create_byte_array_high_throughput(
        data_filepath=data_filepath, perf_filepath=perf_filepath, value=value
    )
    if loops > -1:
        for iteration in range(1, loops + 1):
            logging.info('fill+read iteration %d / %d', iteration + 1, loops)
            write_byte_array_contiguously(sweetspot_byte_array, data_filepath=data_filepath)
            read_bytearray_from_disk(sweetspot_byte_array, data_filepath=data_filepath)
    elif duration > -1:
        start = time.time()
        elapsed = time.time() - start
        iteration = 1
        while elapsed < duration:
            logging.info('fill+read iteration %d until %s > %s', iteration, elapsed, duration)
            write_byte_array_contiguously(sweetspot_byte_array, data_filepath=data_filepath)
            if elapsed > duration:
                logging.info('time exceeded after write')
                break
            read_bytearray_from_disk(sweetspot_byte_array, data_filepath=data_filepath)
            if elapsed > duration:
                logging.info('time exceeded after read')
                break

            iteration += 1
            elapsed = time.time() - start
    else:
        iteration = 1
        while True:
            try:
                logging.info('fill+read iteration %d infinitely', iteration)
                write_byte_array_contiguously(sweetspot_byte_array, data_filepath=data_filepath)
                read_bytearray_from_disk(sweetspot_byte_array, data_filepath=data_filepath)

                iteration += 1
            except KeyboardInterrupt:
                break


def crystaldiskinfo():
    # type: () -> Dict[str, dict]
    global CRYSTALDISKINFO_TXT

    # run crystaldiskinfo, get a text document (each time converting into telemetry data
    cmd = [CRYSTALDISKINFO_EXE, '/CopyExit']
    # logging.debug(subprocess.list2cmdline(cmd))
    _ = subprocess.check_call(cmd, universal_newlines=True)

    # TODO: dynamic crystaldiskinfo txt
    if CRYSTALDISKINFO_TXT == '':
        candidates = [
            os.path.join(os.path.dirname(CRYSTALDISKINFO_EXE), 'DiskInfo.txt'),
            r'C:\ProgramData\chocolatey\lib\crystaldiskinfo.portable\tools\DiskInfo.txt',
            os.path.expanduser(r'~\Desktop\crystaldiskinfo.portable\tools'),
            r'C:\Program Files\CrystalDiskInfo\DiskInfo.txt',
        ]
        for candidate in candidates:
            if os.path.isfile(candidate):
                CRYSTALDISKINFO_TXT = candidate
                break
        if not os.path.isfile(CRYSTALDISKINFO_TXT):
            raise OSError('Could not find DiskInfo.txt! I looked everywhere!')
    with open(CRYSTALDISKINFO_TXT, 'r', encoding='utf-8') as r:
        content = r.read().splitlines()

    crystal_disks = {}  # crystal_disk name to disk number
    crystal_data = {}  # from .txt
    crystal_disk = {}  # from .txt
    crystal_disk_list = []
    line = content.pop(0)
    while content:
        if line.startswith('-- '):
            if 'Disk List' in line:
                while content:
                    line = content.pop(0)
                    if line == '-' * 76:
                        break
                    crystal_disk_list.append(line)

                # logging.debug('crystal_disk_list: %s', json.dumps(crystal_disk_list, indent=2))
                for line in crystal_disk_list:
                    line = line.rstrip()
                    if not line:
                        continue
                    key = line.split(' : ')[0]
                    disk_number = re.findall(r'[X\d]/\d/\d', line)[0][0]  # 5/4/0 means disk 5
                    crystal_disks[key] = disk_number
                # logging.debug('crystal_disks: %s', json.dumps(crystal_disks, indent=2))
            elif 'S.M.A.R.T.' in line:
                # -- S.M.A.R.T. --------------------------------------------------------------
                # ID Cur Wor Thr RawValues(6) Attribute Name
                # 05 100 100 __0 000000000000 Re-Allocated Sector Count
                # 09 100 100 __0 0000000000D4 Power-On Hours Count
                # 0C 100 100 __0 0000000000D2 Power Cycle Count
                # ID RawValues(6) Attribute Name
                # 01 000000000000 Critical Warning
                line = content.pop(0)  # get rid of next line "ID RawValues(6) Attribute Name"
                line = content.pop(0)  # 01 000000000000 Critical Warning
                while line:
                    if not line:
                        break
                    try:
                        mo = re.match(
                            r'(?P<ID>[A-F0-9]{2,})(?P<whocares>[ _0-9]+)? (?P<RawValues>[A-F0-9]{12,}) (?P<AttributeName>.+)',
                            line
                        )
                        dick = mo.groupdict()
                    except Exception:
                        print(repr(line))
                        raise
                    ID, RawValues, AttributeName = dick['ID'], dick['RawValues'], dick['AttributeName']
                    crystal_disk[AttributeName] = int(RawValues, base=16)
                    line = content.pop(0)

        elif line in crystal_disks:
            crystal_disk = {'datetime': str(datetime.datetime.now())}
            disk_number = crystal_disks[line]
            line = content.pop(0)  # remove first ('-' * 76)
            line = content.pop(0)  # get line right after, Model:
            while not line.startswith('-- '):
                line = line.rstrip()
                if not line:
                    break
                try:
                    key, val = line.split(' :')
                except Exception:
                    print(repr(line))
                    raise
                crystal_disk[key.strip()] = val.strip()
                line = content.pop(0)

            crystal_data[disk_number] = crystal_disk

        line = content.pop(0)

    # logging.debug('disks: %s', json.dumps(crystal_disks, indent=2))
    # logging.debug('data: %s', json.dumps(crystal_data, indent=2))
    return crystal_data


def get_keys_from_dicts(*dicts):
    keys = []
    for dick in dicts:
        for key in dick.keys():
            if key not in keys:
                keys.append(key)
    return keys


def main():
    global CRYSTALDISKINFO_EXE
    parser = argparse.ArgumentParser(prog='fill-the-drive', description=__doc__, formatter_class=NiceFormatter)
    operations = parser.add_subparsers(help='different operations we can do')

    op0 = operations.add_parser(
        'perf',
        help='analyze the performance of the drive which determines a file size that is fastest to write',
        description=create_byte_array_high_throughput.__doc__,
        formatter_class=NiceFormatter,
    )
    op0.set_defaults(operation='perf')

    op1 = operations.add_parser(
        'fill',
        help='fill up the disk',
        description=write_byte_array_contiguously.__doc__,
        formatter_class=NiceFormatter,
    )
    op1.set_defaults(operation='fill')
    group = op1.add_argument_group('operation specific')
    group.add_argument('--size', type=int, default=SIZE, help='size in killobytes, so --size * 1024B')

    op2 = operations.add_parser(
        'perf+fill',
        help='do perf+fill',
        description=write_byte_array_contiguously.__doc__,
        formatter_class=NiceFormatter,
    )
    op2.set_defaults(operation='perf+fill')
    group = op2.add_argument_group('operation specific')

    op3 = operations.add_parser(
        'loop',
        help='repeatedly write to the disk for some size and duration',
        description=write_byte_array_continuously.__doc__,
        formatter_class=NiceFormatter,
    )
    op3.set_defaults(operation='loop')
    group = op3.add_argument_group('operation specific')
    group.add_argument('--size', type=int, default=SIZE, help='size in killobytes, so --size * 1024B')
    group.add_argument(
        '--duration',
        type=int,
        default=DURATION,
        help='either run till --duration in seconds or --iteration is exceeded'
    )
    group.add_argument(
        '--iterations',
        type=int,
        default=ITERATIONS,
        help='either run till --duration in seconds or --iteration is exceeded'
    )

    op4 = operations.add_parser(
        'write',
        help='make a new file with a particular size',
        description=generate_and_write_bytearray.__doc__,
        formatter_class=NiceFormatter,
    )
    op4.set_defaults(operation='write')
    group = op4.add_argument_group('operation specific')
    group.add_argument('--size', type=int, default=SIZE, help='size in bytes')
    group.add_argument(
        '--no-optimizations',
        '--no_optimizations',
        action='store_true',
        help='generate the FULL byte_array in memory, no matter how unreasonable.'
    )

    op5 = operations.add_parser(
        'perf+write',
        help='make a new file with a particular size',
        description=generate_and_write_bytearray.__doc__,
        formatter_class=NiceFormatter,
    )
    op5.set_defaults(operation='perf+write')
    group = op5.add_argument_group('operation specific')
    group.add_argument('--size', type=int, default=SIZE, help='size in bytes')
    group.add_argument(
        '--no-optimizations',
        '--no_optimizations',
        action='store_true',
        help='generate the FULL byte_array in memory, no matter how unreasonable.'
    )

    op6 = operations.add_parser(
        'health',
        help='evaluate all disks for their health and track the movements',
        description=generate_and_write_bytearray.__doc__,
        formatter_class=NiceFormatter,
    )
    op6.set_defaults(operation='health')
    group = op6.add_argument_group('operation specific')
    group.add_argument(
        '--ignore-partitions', type=str, nargs='*', default=['C', 'D', 'E'], help='if known partitions, ignore these'
    )
    group.add_argument('--period', type=float, default=PERIOD, help='telemetry poll period')

    op7 = operations.add_parser(
        'perf+fill+read',
        help='fill disk, readback',
        description=perf_fill_read.__doc__,
        formatter_class=NiceFormatter,
    )
    op7.set_defaults(operation='perf+fill+read')
    group = op7.add_argument_group('operation specific')
    group.add_argument('--loops', type=int, default=-1, help='default infinitely')
    group.add_argument('--duration', type=int, default=-1, help='default infinitely, measured in seconds')

    op8 = operations.add_parser(
        'smartmon',
        help='repeatedly run crystaldiskinfo',
        description='TODO: plz',  # TODO: plz
        formatter_class=NiceFormatter,
    )
    op8.set_defaults(operation='smartmon')
    group = op8.add_argument_group('operation specific')
    group.add_argument('--period', type=float, default=PERIOD, help='telemetry poll period')

    for op in [op0, op1, op2, op3, op4, op5, op6, op7, op8]:
        group = op.add_argument_group('general')
        group.add_argument(
            '--data-filepath', type=str, default=DATA_FILEPATH, help='where to dump the file that fills the disk.'
        )
        group.add_argument(
            '--perf-filepath', type=str, default=PERF_FILEPATH, help='where to dump the csv with performance data.'
        )
        group.add_argument(
            '--value', type=int, default=VALUE, help='fill bytearray with a constant byte value, default means random.'
        )
        group.add_argument('--log-level', type=str, default=LOG_LEVEL, choices=LOG_LEVELS, help='log level')

    args = parser.parse_args()
    validate_kwargs(**vars(args))

    logging.basicConfig(
        format='%(asctime)s - %(levelname)10s - %(funcName)48s - %(message)s', level=args.log_level, stream=sys.stdout
    )
    logging.info('starting %r', args.operation)

    if args.operation == 'perf':
        create_byte_array_high_throughput(
            value=args.value, data_filepath=args.data_filepath, perf_filepath=args.perf_filepath
        )

    elif args.operation == 'perf+fill':
        sweetspot_byte_array = create_byte_array_high_throughput(
            data_filepath=args.data_filepath, perf_filepath=args.perf_filepath, value=args.value
        )
        write_byte_array_contiguously(sweetspot_byte_array, data_filepath=args.data_filepath)

    elif args.operation in ['fill', 'loop']:
        byte_array = create_bytearray_killobytes(args.size, value=args.value)
        if args.operation == 'fill':
            write_byte_array_contiguously(byte_array, data_filepath=args.data_filepath)
        elif args.operation == 'loop':
            write_byte_array_continuously(
                byte_array, data_filepath=args.data_filepath, duration=args.duration, iterations=args.iterations
            )

    elif args.operation == 'write':
        generate_and_write_bytearray(
            args.size, value=args.value, no_optimizations=args.no_optimizations, data_filepath=args.data_filepath
        )

    elif args.operation == 'perf+write':
        sweetspot_byte_array = create_byte_array_high_throughput(
            data_filepath=args.data_filepath, perf_filepath=args.perf_filepath, value=args.value
        )
        write_bytearray_to_disk(sweetspot_byte_array, size=args.size, data_filepath=args.data_filepath)

    elif args.operation == 'perf+fill+read':
        perf_fill_read(
            data_filepath=args.data_filepath,
            perf_filepath=args.perf_filepath,
            value=args.value,
            loops=args.loops,
            duration=args.duration
        )

    elif args.operation == 'smartmon':
        logging.debug('reading crystaldiskinfo')
        crystal_data = crystaldiskinfo()
        crystaldisk_keys = get_keys_from_dicts(*list(crystal_data.values()))
        if not os.path.isfile(args.perf_filepath):
            with open(args.perf_filepath, 'w', encoding='utf-8', newline='') as w:
                writer = csv.DictWriter(w, fieldnames=crystaldisk_keys)
                writer.writeheader()
                for value in crystal_data.values():
                    writer.writerow(value)
        else:
            # combine old and new keys
            old_df = pd.from_csv(args.perf_filepath)
            new_df = pd.DataFrame(crystal_data.values())
            df = pd.concat([old_df, new_df])
            df.to_csv(index=False)
            crystaldisk_keys = df.columns.tolist()

        try:
            started = datetime.datetime.now()
            while True:
                now = datetime.datetime.now()
                logging.info('elapsed: %s', now - started)
                crystal_data = crystaldiskinfo()
                with open(args.perf_filepath, 'a', encoding='utf-8', newline='') as a:
                    writer = csv.DictWriter(a, fieldnames=crystaldisk_keys)
                    for value in crystal_data.values():
                        writer.writerow(value)
                time.sleep(args.period)
        except KeyboardInterrupt:
            logging.warning('ctrl + c detected! killing processes, removing resources...')

    elif args.operation == 'health':
        try:
            output = subprocess.check_output(
                ['where.exe' if sys.platform == 'win32' else 'which', CRYSTALDISKINFO_EXE], universal_newlines=True
            )
            for line in output.splitlines():
                strip = line.strip()
                if os.path.isfile(strip):
                    CRYSTALDISKINFO_EXE = strip
                    break
            if not os.path.isfile(strip):
                raise OSError(f'Could not find "{CRYSTALDISKINFO_EXE}"!')
        except subprocess.CalledProcessError:
            logging.warning('WARNING: CrystalDiskInfo not installed or not on path!')
            return 1

        if sys.platform != 'win32':
            raise NotImplementedError(sys.platform)

        logging.debug('checking admin access')
        admin_ps1 = os.path.join(SCRIPT_DIRPATH, r"scripts\win32\admin.ps1")
        subprocess.check_call(['powershell', admin_ps1])
        logging.info('admin detected!')

        # get current partitions
        logging.debug('sanitizing unwanted partitions')
        read_partitions_ps1 = os.path.join(SCRIPT_DIRPATH, r"scripts\win32\read-partitions.ps1")
        cmd = ['powershell', read_partitions_ps1]
        logging.debug(subprocess.list2cmdline(cmd))
        output = subprocess.check_output(cmd, universal_newlines=True)
        read_partitions = json.loads(output)
        logging.debug('partitions: %s', json.dumps(read_partitions, indent=2))
        logging.info('read partitions!')

        logging.debug('filter out all partitions that dont belong')
        drive_letters_to_remove = [key for key in read_partitions if key not in args.ignore_partitions]
        logging.debug('removing drive letters: %s', drive_letters_to_remove)
        disk_numbers = [val['DiskNumber'] for key, val in read_partitions.items() if key not in args.ignore_partitions]
        logging.debug('will operate on drive numbers: %s', disk_numbers)
        logging.info('found disks and old partitions!')

        if drive_letters_to_remove:
            logging.debug('remove partitions so they return to raw')
            delete_partitions_ps1 = os.path.join(SCRIPT_DIRPATH, r"scripts\win32\delete-partitions.ps1")
            cmd = ['powershell', delete_partitions_ps1, '-DriveLetters', ','.join(drive_letters_to_remove)]
            logging.debug(subprocess.list2cmdline(cmd))
            output = subprocess.check_output(cmd, universal_newlines=True)
            logging.debug(output)
            logging.info('removed unwanted partitions!')

        logging.debug('make new partitions')
        create_partitions_ps1 = os.path.join(SCRIPT_DIRPATH, r"scripts\win32\create-partitions.ps1")
        cmd = ['powershell', create_partitions_ps1, '-DriveLetters', ','.join(drive_letters_to_remove)]
        logging.debug(subprocess.list2cmdline(cmd))
        output = subprocess.check_output(cmd, universal_newlines=True)
        create_partitions_sentinel = "Begin Output Parsing Here:"
        logging.debug(output)
        output = output[output.find(create_partitions_sentinel) + len(create_partitions_sentinel) + 1:].strip()
        logging.debug(output)
        drive_number_to_letter_dict = json.loads(output)
        logging.debug('will operate on drive numbers and letters: %s', drive_number_to_letter_dict)
        logging.info('created new partitions!')

        logging.debug('reading disks')
        read_disks_ps1 = os.path.join(SCRIPT_DIRPATH, r"scripts\win32\read-disks.ps1")
        cmd = ['powershell', read_disks_ps1]
        logging.debug(subprocess.list2cmdline(cmd))
        output = subprocess.check_output(cmd, universal_newlines=True)
        read_disks = json.loads(output)
        logging.debug('disks: %s', json.dumps(read_disks, indent=2))
        logging.debug('read disk info!')

        logging.debug('reading crystaldiskinfo')
        crystal_data = crystaldiskinfo()
        crystaldisk_keys = get_keys_from_dicts(*list(crystal_data.values()))
        if not os.path.isfile(args.perf_filepath):
            with open(args.perf_filepath, 'w', encoding='utf-8', newline='') as w:
                writer = csv.DictWriter(w, fieldnames=crystaldisk_keys)
                writer.writeheader()
        with open(args.perf_filepath, 'a', encoding='utf-8', newline='') as a:
            writer = csv.DictWriter(a, fieldnames=crystaldisk_keys)
            for value in crystal_data.values():
                writer.writerow(value)
        logging.info('read crystaldiskinfo!')

        logging.debug('starting perf+fill')
        started = datetime.datetime.now()
        popens = []
        for drive_number, drive_letter in drive_number_to_letter_dict.items():
            data_filepath = f'{drive_letter}:/{drive_number}-perf+fill.dat'
            perf_filepath = f'{drive_letter}:/{drive_number}-perf+fill.csv'
            stdout = f'{drive_letter}:/{drive_number}-perf+fill.stdout'
            stderr = f'{drive_letter}:/{drive_number}-perf+fill.stderr'
            cmd = [
                sys.executable,
                os.path.abspath(__file__),
                'perf+fill',
                '--data-filepath',
                data_filepath,
                '--perf-filepath',
                perf_filepath,
                '--value',
                str(args.value),
                '--log-level',
                args.log_level,
            ]
            logging.debug('drive %s (%s): %s', drive_number, drive_letter, subprocess.list2cmdline(cmd))
            with open(stdout, 'wb') as sout, open(stderr, 'wb') as serr:
                popen = subprocess.Popen(cmd, stdout=sout, stderr=serr)
                popens.append(popen)

        logging.info('launching multi perf+fill on %d partitions/drives...', len(drive_number_to_letter_dict))
        try:
            while True:
                now = datetime.datetime.now()
                logging.info('elapsed: %s', now - started)
                crystal_data = crystaldiskinfo()
                with open(args.perf_filepath, 'a', encoding='utf-8', newline='') as a:
                    writer = csv.DictWriter(a, fieldnames=crystaldisk_keys)
                    for value in crystal_data.values():
                        writer.writerow(value)
                if all([popen.poll() is not None for popen in popens]):
                    logging.info('All perf+ fill finished!')
                    break
                time.sleep(args.period)
        except KeyboardInterrupt:
            logging.warning('ctrl + c detected! killing processes, removing resources...')

        logging.info('closing resources...')
        for popen in popens:
            if popen.poll() is None:
                popen.kill()
                subprocess.Popen(['taskkill', '/pid', str(popen.pid), '/f', '/t'], shell=True).wait()
        for drive_number, drive_letter in drive_number_to_letter_dict.items():
            data_filepath = os.path.abspath(f'{drive_letter}:/{drive_number}-perf+fill.dat')
            perf_filepath = os.path.abspath(f'{drive_letter}:/{drive_number}-perf+fill.csv')
            stdout = os.path.abspath(f'{drive_letter}:/{drive_number}-perf+fill.stdout')
            stderr = os.path.abspath(f'{drive_letter}:/{drive_number}-perf+fill.stderr')

            dirpath = os.path.dirname(args.perf_filepath)
            for filepath in [data_filepath, perf_filepath, stdout, stderr]:
                destination = os.path.join(dirpath, os.path.basename(filepath))
                logging.info('output: "%s"', destination)
                if os.path.isfile(destination):
                    try:
                        os.remove(destination)
                    except Exception:
                        logging.error('unable to delete ""%s', destination)

            try:
                os.remove(data_filepath)
            except Exception:
                logging.error('unable to delete ""%s', data_filepath)
            for src in [perf_filepath, stdout, stderr]:
                if os.path.isfile(src):
                    shutil.move(src, dirpath)

        logging.debug('removing partitions...')
        delete_partitions_ps1 = os.path.join(SCRIPT_DIRPATH, r"scripts\win32\delete-partitions.ps1")
        cmd = [
            'powershell', delete_partitions_ps1, '-Offline', '-DriveLetters',
            ','.join(drive_number_to_letter_dict.values())
        ]
        logging.debug(subprocess.list2cmdline(cmd))
        output = subprocess.check_output(cmd, universal_newlines=True)
        logging.debug(output)
        logging.info('removed all used partitions!')

    logging.info('perf-filepath: "%s"', args.perf_filepath)
    logging.info('done %r', args.operation)


if __name__ == '__main__':
    main()
